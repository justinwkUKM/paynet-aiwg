{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24cd6f80-e7b7-4444-95e9-3ee64d1bdc06",
   "metadata": {},
   "source": [
    "## MCP Demo Notebook\n",
    "\n",
    "This notebook demonstrates how to use the MCP clients in Python.\n",
    "\n",
    "It covers:\n",
    "- How to directly connect to an MCP server, list available tools, and invoke a tool.\n",
    "- How to use AI agents (with LangGraph and LangChain) to interact with MCP tools in a conversational way.\n",
    "\n",
    "Use this notebook as a reference for integrating and experimenting with MCP in your own projects.\n",
    "\n",
    "**Author:** [Gregory Tan](gregory.tanyj@paynet.my), Senior AI Engineer @ AI R&D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe3d1f0-de89-4efb-9ada-ed8f6cfbbab5",
   "metadata": {},
   "source": [
    "---\n",
    "### Section 1: Directly Invoking MCP Client\n",
    "\n",
    "Directly connect to the MCP server, list available tools, and call a tool directly.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a885526c-a176-46a1-bf93-b6af70cdee5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (01) Installing Necessary Libraries\n",
    "!pip install -r requirements.txt -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5590f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (01) Importing Necessary Libraries \n",
    "from mcp import ClientSession\n",
    "from mcp.client.streamable_http import streamablehttp_client\n",
    "import os, asyncio, subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31afeb7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCP Server Started | PID 37537\n"
     ]
    }
   ],
   "source": [
    "# (02) Start MCP server in the background\n",
    "MCP_SERVER_FILE = \"mcp_server.py\"\n",
    "LOG_FILE = \"output.log\"\n",
    "\n",
    "# Clean up old processes and logs\n",
    "os.system(f\"pkill -f {MCP_SERVER_FILE}\")\n",
    "open(LOG_FILE, \"w\").close()\n",
    "\n",
    "# Start new process\n",
    "process = subprocess.Popen(\n",
    "    [\"python\", MCP_SERVER_FILE],\n",
    "    stdout=open(LOG_FILE, \"w\"),\n",
    "    stderr=subprocess.STDOUT\n",
    ")\n",
    "\n",
    "print(f\"MCP Server Started | PID {process.pid}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d59c243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     Started server process [37537]\n",
      "INFO:     Waiting for application startup.\n",
      "\u001b[2;36m[09/23/25 14:53:52]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m StreamableHTTP       \u001b]8;id=289818;file:///opt/anaconda3/envs/demo/lib/python3.12/site-packages/mcp/server/streamable_http_manager.py\u001b\\\u001b[2mstreamable_http_manager.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=102728;file:///opt/anaconda3/envs/demo/lib/python3.12/site-packages/mcp/server/streamable_http_manager.py#110\u001b\\\u001b[2m110\u001b[0m\u001b]8;;\u001b\\\n",
      "\u001b[2;36m                    \u001b[0m         session manager      \u001b[2m                              \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         started              \u001b[2m                              \u001b[0m\n",
      "INFO:     Application startup complete.\n",
      "INFO:     Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)\n"
     ]
    }
   ],
   "source": [
    "# (02) Check if MCP server is running\n",
    "!tail -n 20 $LOG_FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8415088e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # (Optional) Stop MCP server\n",
    "# process.terminate()\n",
    "# print(f\"MCP Server Stopped | PID {process.pid}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3994a3d-ae15-409b-a269-e09e3e013a51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to MCP server!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# (03) Interact with MCP Server\n",
    "headers = {\n",
    "    # \"Authorization\": \"Bearer sk-1234\"  # Auth Header\n",
    "}\n",
    "\n",
    "# Connect to server\n",
    "async with streamablehttp_client(\"http://127.0.0.1:8000/mcp\", headers=headers) as (reader, writer, _):\n",
    "    async with ClientSession(reader, writer) as session:\n",
    "        # Initialize connection\n",
    "        await session.initialize()\n",
    "        print(\"Connected to MCP server!\\n\")\n",
    "\n",
    "        # # List Tools\n",
    "        # tools_list = await session.list_tools()\n",
    "        # print(\"The tools list are below:\")\n",
    "        # for tool in tools_list.tools:\n",
    "        #     print(f\"- {tool.name}: {tool.description}\")\n",
    "        \n",
    "        # # Call Tools (get_temperature)\n",
    "        # result = await session.call_tool(\"get_temperature\", {\"city\": \"kuala lumpur\"})\n",
    "        # print(\"Calling get_temperature tool:\")\n",
    "        # print(\"Result: \", result.content[-1].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e16a42-fc06-48f4-96b4-5ef866c86def",
   "metadata": {},
   "source": [
    "---\n",
    "### Section 2: Using AI Agents (LangGraph) to Chat with MCP\n",
    "\n",
    "This section demonstrates how to use an AI agent (via LangGraph) to interact with MCP tools in a conversational way.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd179df7-7dcd-4566-a655-4d687c3577bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (04) Import libraries for LangGraph\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_litellm import ChatLiteLLM\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langchain_mcp_adapters.client import MultiServerMCPClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f60ae7d-b2bc-4326-8acd-5d3b8ffa5799",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (04) Setup LangGraph with LiteLLM and MCP Client\n",
    "MODEL = \"bedrock-claude-3-5-sonnet\"\n",
    "LITELLM_BASE_URL = \"your_litellm_url_here\"\n",
    "LITELLM_API_KEY = \"your_litellm_key_here\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ae0d7c6-a7ee-4eed-acb3-a5731637dbd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (05) Initialize components for the AI agent\n",
    "model = ChatLiteLLM(\n",
    "    model=MODEL, # configured in LiteLLM\n",
    "    api_base=LITELLM_BASE_URL, # URL to the LiteLLM server\n",
    "    api_key=LITELLM_API_KEY, # API key for LiteLLM\n",
    "    custom_llm_provider=\"openai\", # mimic OpenAI API\n",
    "    temperature=0.0, # temperature for the model\n",
    "    streaming=True, # enable streaming\n",
    "    verbose=True, # enable verbose logging\n",
    ")\n",
    "checkpointer = InMemorySaver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d03944a2-b8d4-49de-aa0d-32dd611746c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (05) Set MCP Tools to LangGraph\n",
    "client = MultiServerMCPClient(\n",
    "    {\n",
    "        \"mcp_server\": {\n",
    "            \"url\": \"http://127.0.0.1:8000/mcp\",\n",
    "            \"headers\": headers,\n",
    "            \"transport\": \"streamable_http\",\n",
    "        },\n",
    "    }\n",
    ")\n",
    "tools = await client.get_tools()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "94e2a002-d9ad-4d05-9675-5a02e498e451",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (05) Create Agent with MCP Tools\n",
    "agent = create_react_agent(\n",
    "    model=model,\n",
    "    tools=tools,\n",
    "    prompt=\"\"\"\n",
    "    You are a helpful weather assistant. \n",
    "    When the user asks for the weather in a specific city, use the tools to find the information. \n",
    "    If the tool returns an error, inform the user politely.\n",
    "    If the tool is successful, present the weather report clearly.\n",
    "    \"\"\",\n",
    "    checkpointer=checkpointer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1967620b-a062-495a-890d-1c93b42c1cd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "hi! i am from kuala lumpur\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hello! It's nice to meet you. I understand that you're from Kuala Lumpur, the capital city of Malaysia. Since you've mentioned your location, would you like to know about the current weather conditions in Kuala Lumpur? I can provide you with information about the temperature and wind speed if you're interested. Just let me know if you'd like me to check that for you.\n"
     ]
    }
   ],
   "source": [
    "# (06) Interact with the agent\n",
    "# Example 1: Simple interaction\n",
    "async for response in agent.astream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"hi! i am from kuala lumpur\"}]},\n",
    "    {\"configurable\": {\"thread_id\": \"1\"}},\n",
    "    stream_mode=\"values\",\n",
    "):\n",
    "    response[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "26cf713d-f8ad-433c-a25c-6fefd565a838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What is the weather in my city?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Certainly! I'd be happy to check the weather for you in Kuala Lumpur. I'll use our weather tools to fetch the current temperature and wind speed for your city. Let me do that for you right now.\n",
      "Tool Calls:\n",
      "  get_temperature (tooluse_w61z2WUGT0q5ahHt6s9-cA)\n",
      " Call ID: tooluse_w61z2WUGT0q5ahHt6s9-cA\n",
      "  Args:\n",
      "    city: Kuala Lumpur\n",
      "  get_windspeed (tooluse_n5quki6qRFSo6yZ1hPM2tg)\n",
      " Call ID: tooluse_n5quki6qRFSo6yZ1hPM2tg\n",
      "  Args:\n",
      "    city: Kuala Lumpur\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: get_windspeed\n",
      "\n",
      "{\n",
      "  \"status\": \"success\",\n",
      "  \"report\": \"The windspeed in Kuala Lumpur is 12.7km/h\"\n",
      "}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Great! I've got the current weather information for Kuala Lumpur. Here's the report:\n",
      "\n",
      "Temperature: The temperature in Kuala Lumpur is 33.0¬∞C (91.4¬∞F). It's quite warm today!\n",
      "\n",
      "Wind Speed: The wind speed in Kuala Lumpur is 12.7 km/h (7.9 mph). This is a light breeze.\n",
      "\n",
      "Overall, it seems like a warm day in Kuala Lumpur with a gentle breeze. It might be a good idea to stay hydrated and seek shade if you're planning to be outdoors. Is there anything else you'd like to know about the weather or any other information I can help you with?\n"
     ]
    }
   ],
   "source": [
    "# Example 2: Weather inquiry\n",
    "async for response in agent.astream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"What is the weather in my city?\"}]},\n",
    "    {\"configurable\": {\"thread_id\": \"1\"}},\n",
    "    stream_mode=\"values\",\n",
    "):\n",
    "    response[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813e28a2-081d-449c-b8ee-ba3d7105f838",
   "metadata": {},
   "source": [
    "---\n",
    "### Section 3: Using MCP Servers from Online\n",
    "\n",
    "This section shows how to connect to and use MCP servers that are hosted online, not just on your local machine.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f41dd79",
   "metadata": {},
   "source": [
    "**VirusTotal MCP**\n",
    "\n",
    "**Description:**\n",
    "\n",
    "The VirusTotal MCP server can be used for IOC (Indicator of Compromise) scanning, such as checking file hashes, URLs, IPs, or domains against VirusTotal's threat intelligence database.  \n",
    "You must provide your own VirusTotal API keys to use this service.\n",
    "\n",
    "**Repository Link:**  \n",
    "- [VirusTotal API Key](https://www.virustotal.com/gui/my-apikey)\n",
    "- [VirusTotal MCP](https://glama.ai/mcp/servers/@BurtTheCoder/mcp-virustotal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f15c63d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1G\u001b[0K‚†ô\u001b[1G\u001b[0K‚†π\u001b[1G\u001b[0K‚†∏\u001b[1G\u001b[0K‚†º\u001b[1G\u001b[0K‚†¥\u001b[1G\u001b[0K‚†¶\u001b[1G\u001b[0K‚†ß\u001b[1G\u001b[0K‚†á\u001b[1G\u001b[0K‚†è\u001b[1G\u001b[0K‚†ã\u001b[1G\u001b[0K‚†ô\u001b[1G\u001b[0K‚†π\u001b[1G\u001b[0K‚†∏\u001b[1G\u001b[0K‚†º\u001b[1G\u001b[0K‚†¥\u001b[1G\u001b[0K‚†¶\u001b[1G\u001b[0K‚†ß\u001b[1G\u001b[0K‚†á\u001b[1G\u001b[0K‚†è\u001b[1G\u001b[0K‚†ã\u001b[1G\u001b[0K‚†ô\u001b[1G\u001b[0K‚†π\u001b[1G\u001b[0K‚†∏\u001b[1G\u001b[0K‚†º\u001b[1G\u001b[0K‚†¥\u001b[1G\u001b[0K‚†¶\u001b[1G\u001b[0K‚†ß\u001b[1G\u001b[0K‚†á\u001b[1G\u001b[0K‚†è\u001b[1G\u001b[0K‚†ã\u001b[1G\u001b[0K‚†ô\u001b[1G\u001b[0K‚†π\u001b[1G\u001b[0K‚†∏\u001b[1G\u001b[0K‚†º\u001b[1G\u001b[0K‚†¥\u001b[1G\u001b[0K‚†¶\u001b[1G\u001b[0K‚†ß\u001b[1G\u001b[0K‚†á\u001b[1G\u001b[0K‚†è\u001b[1G\u001b[0K‚†ã\u001b[1G\u001b[0K‚†ô\u001b[1G\u001b[0K‚†π\u001b[1G\u001b[0K\n",
      "changed 40 packages in 4s\n",
      "\u001b[1G\u001b[0K‚†π\u001b[1G\u001b[0K\n",
      "\u001b[1G\u001b[0K‚†π\u001b[1G\u001b[0K9 packages are looking for funding\n",
      "\u001b[1G\u001b[0K‚†π\u001b[1G\u001b[0K  run `npm fund` for details\n",
      "\u001b[1G\u001b[0K‚†π\u001b[1G\u001b[0K"
     ]
    }
   ],
   "source": [
    "# (07) Installation of VirusTotal MCP\n",
    "!npm install -g @burtthecoder/mcp-virustotal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db89eddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (07) Set of VirusTotal API Key\n",
    "VIRUSTOTAL_API_KEY = \"your_virustotal_api_key_here\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "485a1360-f977-488a-a380-16d72a759d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (08) Add VirusTotal MCP tool to the existing client\n",
    "new_client = MultiServerMCPClient(\n",
    "    {\n",
    "        \"mcp_server\": {\n",
    "            \"url\": \"http://localhost:8000/mcp\",\n",
    "            \"headers\": headers,\n",
    "            \"transport\": \"streamable_http\",\n",
    "        },\n",
    "        \"secuity_tools_mcp\": {\n",
    "            \"command\": \"node\",\n",
    "            \"args\": [f\"{subprocess.check_output([\"npm\", \"root\", \"-g\"]).decode().strip()}/@burtthecoder/mcp-virustotal/build/index.js\"],\n",
    "            \"env\": { \"VIRUSTOTAL_API_KEY\": VIRUSTOTAL_API_KEY },\n",
    "            \"transport\": \"stdio\",\n",
    "        },\n",
    "    }\n",
    ") \n",
    "new_tools = await new_client.get_tools()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4d3ee9d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before:  2 | After:  9\n"
     ]
    }
   ],
   "source": [
    "# (08) Check the number of tools before and after adding VirusTotal MCP\n",
    "print(\"Before: \", len(tools), \"| After: \", len(new_tools))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "08af357c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (09) Create an agent with the new tools\n",
    "agent_new = create_react_agent(\n",
    "    model=model,\n",
    "    tools=new_tools,\n",
    "    prompt=\"Use the toots you have to answer the user's questions.\",\n",
    "    checkpointer=checkpointer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "db3a848b-d70a-4809-92e2-7d6e10f15fc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Investigate if this hash safe? 435e67c0fcb0ac34b17754527f264833553ada8fa222aa37a0841b3faf6324a5\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Certainly! I'll investigate the safety of the hash you've provided: 435e67c0fcb0ac34b17754527f264833553ada8fa222aa37a0841b3faf6324a5. This appears to be a SHA-256 hash. I'll use our file analysis tool to check if this file is safe or potentially malicious.\n",
      "Tool Calls:\n",
      "  get_file_report (tooluse_i_uRBILzTea7B6RKSLKtfQ)\n",
      " Call ID: tooluse_i_uRBILzTea7B6RKSLKtfQ\n",
      "  Args:\n",
      "    hash: 435e67c0fcb0ac34b17754527f264833553ada8fa222aa37a0841b3faf6324a5\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: get_file_report\n",
      "\n",
      "üìÅ File Analysis Results\n",
      "üîë Hashes:\n",
      "‚Ä¢ SHA-256: 435e67c0fcb0ac34b17754527f264833553ada8fa222aa37a0841b3faf6324a5\n",
      "‚Ä¢ SHA-1: efd04b092e54f150a2cc79f4fe088a770192182f\n",
      "‚Ä¢ MD5: 3e9f28ce8778710c949f73e1d678d462\n",
      "‚Ä¢ VHash: 0b5c275a50e655cfa829779903c9b5b3\n",
      "üìÑ File Information:\n",
      "‚Ä¢ Name: vfxue.exe\n",
      "‚Ä¢ Type: ELF\n",
      "‚Ä¢ Size: 300.78 KB\n",
      "‚Ä¢ First Seen: 9/22/2025, 4:24:06 AM\n",
      "‚Ä¢ Last Modified: 9/23/2025, 2:31:29 PM\n",
      "‚Ä¢ Times Submitted: 1\n",
      "‚Ä¢ Unique Sources: 1\n",
      "üìä Analysis Statistics:\n",
      "Detection Results:\n",
      "üî¥ Malicious: 31 (48.4%)\n",
      "‚ö†Ô∏è  Suspicious: 0 (0.0%)\n",
      "‚úÖ Clean: 0 (0.0%)\n",
      "‚ö™ Undetected: 33 (51.6%)\n",
      "üìä Total Scans: 64\n",
      "üë• Community Feedback:\n",
      "‚Ä¢ Reputation Score: -1\n",
      "‚Ä¢ Harmless Votes: 0\n",
      "‚Ä¢ Malicious Votes: 1\n",
      "üè∑Ô∏è Tags:\n",
      "‚Ä¢ elf\n",
      "üî∞ Popular Engines Results:\n",
      "‚Ä¢ Symantec: Linux.Mirai üî¥\n",
      "‚Ä¢ Kaspersky: HEUR:Backdoor.Linux.Mirai.gen üî¥\n",
      "‚Ä¢ Microsoft: Trojan:Linux/Xaynnalc.A!xp üî¥\n",
      "\n",
      "üîó Relationships:\n",
      "\n",
      "behaviours (0 items):\n",
      "\n",
      "contacted_domains (0 items):\n",
      "\n",
      "contacted_ips (0 items):\n",
      "\n",
      "contacted_urls (0 items):\n",
      "\n",
      "dropped_files (0 items):\n",
      "\n",
      "execution_parents (0 items):\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Based on the analysis of the hash 435e67c0fcb0ac34b17754527f264833553ada8fa222aa37a0841b3faf6324a5, I can provide you with the following information:\n",
      "\n",
      "1. File Identification:\n",
      "   - The file is named \"vfxue.exe\"\n",
      "   - It's an ELF (Executable and Linkable Format) file, typically used in Linux systems\n",
      "   - File size: 300.78 KB\n",
      "\n",
      "2. Detection Results:\n",
      "   - Out of 64 total scans:\n",
      "     - 31 (48.4%) detected it as malicious\n",
      "     - 33 (51.6%) did not detect any threats\n",
      "   - No engines marked it as suspicious or clean\n",
      "\n",
      "3. Community Feedback:\n",
      "   - The file has a negative reputation score of -1\n",
      "   - It has received 1 malicious vote and 0 harmless votes\n",
      "\n",
      "4. Antivirus Detections:\n",
      "   - Symantec identified it as \"Linux.Mirai\"\n",
      "   - Kaspersky labeled it as \"HEUR:Backdoor.Linux.Mirai.gen\"\n",
      "   - Microsoft detected it as \"Trojan:Linux/Xaynnalc.A!xp\"\n",
      "\n",
      "5. Additional Information:\n",
      "   - The file was first seen on 9/22/2025 and last modified on 9/23/2025\n",
      "   - It has been submitted once from a unique source\n",
      "   - It's tagged as \"elf\" (confirming its file type)\n",
      "\n",
      "Conclusion: This file is NOT safe. There are strong indicators that this file is malicious:\n",
      "\n",
      "1. Nearly half of the antivirus engines detected it as a threat.\n",
      "2. It's being identified as a variant of the Mirai malware, which is a known botnet used for DDoS attacks.\n",
      "3. Major antivirus providers (Symantec, Kaspersky, Microsoft) have flagged it as malicious.\n",
      "4. The community has given it a negative reputation score.\n",
      "\n",
      "Recommendation: Do not run or interact with this file. If it's on your system, you should consider removing it and running a full system scan with up-to-date antivirus software. If you've already executed this file, you should take immediate steps to secure your system, including disconnecting from the network, changing passwords, and seeking professional IT security assistance.\n",
      "\n",
      "Is there anything else you'd like to know about this file or any other cybersecurity concerns you have?\n"
     ]
    }
   ],
   "source": [
    "# (10) Interact with the agent\n",
    "# Example 3: Updated interaction with VirusTotal tool\n",
    "async for response in agent_new.astream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"Investigate if this hash safe? 435e67c0fcb0ac34b17754527f264833553ada8fa222aa37a0841b3faf6324a5\"}]},\n",
    "    {\"configurable\": {\"thread_id\": \"1\"}},\n",
    "    stream_mode=\"values\",\n",
    "):\n",
    "    response[\"messages\"][-1].pretty_print()   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "demo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
