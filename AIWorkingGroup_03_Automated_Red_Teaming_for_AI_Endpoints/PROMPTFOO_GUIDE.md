# Promptfoo Guide

## Table of Contents
- [Chatbot Setup](#chatbot-setup)
- [Promptfoo Installation](#promptfoo-installation)
- [Getting Started with Red Teaming](#getting-started-with-red-teaming)
- [Documentation](#documentation)
- [Plugins](#plugins)
- [Strategies](#strategies)

## Chatbot Setup

Before testing with promptfoo, you need to set up and run the FinanceGPT chatbot.

### Prerequisites
- Python 3.8 or higher
- pip (Python package manager)

### Installation Steps

1. **Install Python Dependencies**

   Navigate to the project directory and install the required packages:

   ```bash
   pip install -r requirements.txt
   ```

   This will install:
   - `openai` - OpenAI client library
   - `streamlit` - Web interface framework
   - `python-dotenv` - Environment variable management

2. **Configure Environment Variables**

   Create a `.env` file in the project root with your API credentials:

   ```env
   LLM=your_llm_endpoint_url
   key=your_api_key
   ```

3. **Run the Chatbot**

   Start the Streamlit application:

   ```bash
   streamlit run app.py
   ```

   The chatbot will open in your default web browser, typically at `http://localhost:8501`

4. **Verify the Chatbot is Running**

   You should see the FinanceGPT interface with:
   - A welcome message from the AI assistant
   - A chat input field
   - The "About FinanceGPT" section with capabilities

Now that your chatbot is running, you can proceed to install promptfoo for security testing.

---

## Promptfoo Installation

To install promptfoo globally on your system, run the following command:

```bash
npm install -g promptfoo
```

This will install promptfoo as a global npm package, making it available from any directory in your terminal.

### Prerequisites
- Node.js (version 20 or higher)
- npm/npx (comes with Node.js)

## Getting Started with Red Teaming

Once promptfoo is installed, you can start the red teaming setup by running:

```bash
promptfoo redteam setup
```

This interactive command will guide you through:
- Configuring your LLM provider
- Selecting red teaming plugins
- Setting up test strategies
- Defining your application's purpose and context

## Documentation

For comprehensive documentation, visit the official promptfoo documentation:

**[https://www.promptfoo.dev/docs/](https://www.promptfoo.dev/docs/)**

The documentation includes:
- Detailed configuration guides
- API reference
- Advanced usage patterns
- Integration examples
- Best practices for red teaming

## Plugins

Promptfoo plugins are modular components that enable specific types of security testing and vulnerability detection. They allow you to test your LLM applications against various attack vectors and potential security issues.

### How Plugins Work

Plugins in promptfoo operate by:

1. **Generating Test Cases**: Each plugin generates targeted prompts designed to exploit specific vulnerabilities
2. **Execution**: The generated prompts are sent to your LLM application
3. **Evaluation**: Responses are analyzed to determine if the vulnerability was successfully exploited
4. **Reporting**: Results are compiled into a comprehensive security report

### Common Plugin Types

#### Security Plugins
- **Prompt Injection**: Tests for prompt injection vulnerabilities
- **Jailbreaking**: Attempts to bypass content filters and safety guardrails
- **PII (Personally Identifiable Information)**: Checks if the model leaks sensitive data
- **Harmful Content**: Tests for generation of harmful, toxic, or inappropriate content
- **Hallucination**: Detects when models generate false or misleading information

#### Compliance Plugins
- **Bias Detection**: Identifies potential biases in model outputs
- **OWASP LLM Top 10**: Tests against the OWASP Top 10 vulnerabilities for LLMs
- **Data Privacy**: Ensures compliance with data protection regulations

#### Functional Plugins
- **Overreliance**: Tests if the model makes users over-dependent on potentially incorrect information
- **Excessive Agency**: Checks if the model attempts to perform actions beyond its intended scope

### Configuring Plugins

Plugins can be configured in your `promptfooconfig.yaml` file:

```yaml
redteam:
  plugins:
    - id: 'prompt-injection'
      numTests: 10
    - id: 'jailbreak'
      numTests: 15
    - id: 'harmful:hate'
      numTests: 10
```

## Strategies

Strategies in promptfoo define **how** the red teaming attacks are executed. While plugins determine **what** to test, strategies determine the approach and methodology.

### How Strategies Work

Strategies modify and enhance the base test cases generated by plugins through:

1. **Attack Vector Variation**: Different ways of structuring the same attack
2. **Encoding and Obfuscation**: Transforming inputs to bypass filters
3. **Multi-turn Conversations**: Building up to an attack over multiple interactions
4. **Context Manipulation**: Altering the conversation context to influence responses

### Common Strategy Types

#### Basic Strategies
- **Direct**: Straightforward attack attempts without obfuscation
- **Jailbreak**: Uses known jailbreak techniques and prompt patterns
- **Prompt Injection**: Attempts to override system instructions

#### Advanced Strategies
- **ROT13 Encoding**: Rotates characters by 13 positions to bypass text filters
- **Base64 Encoding**: Encodes malicious content in base64
- **Multilingual**: Uses multiple languages to confuse content filters
- **Crescendo**: Gradually escalates requests over multiple turns

#### Adaptive Strategies
- **Iterative**: Learns from previous attempts and adapts
- **Goat (Generative Offensive Agent Tester)**: Uses an LLM to generate custom attacks
- **Crescendo**: Builds up malicious intent through seemingly innocent questions

### Configuring Strategies

Strategies can be configured alongside plugins:

```yaml
redteam:
  strategies:
    - id: 'jailbreak'
    - id: 'rot13'
    - id: 'multilingual'
      config:
        languages: ['es', 'fr', 'de']
  plugins:
    - id: 'prompt-injection'
    - id: 'harmful'
```

### Strategy + Plugin Combination

The power of promptfoo comes from combining plugins with strategies:

- **Plugin** identifies the vulnerability type (e.g., prompt injection)
- **Strategy** defines the attack method (e.g., using ROT13 encoding)
- **Result**: A comprehensive test that attempts prompt injection using various encoding techniques

Example workflow:
```
Plugin: Harmful Content Detection
  ├─ Strategy: Direct → "Generate harmful content about X"
  ├─ Strategy: ROT13 → "Traregr unezshy pbagrag nobhg K"
  ├─ Strategy: Multilingual → "Générer du contenu nuisible sur X"
  └─ Strategy: Crescendo → Multi-turn conversation leading to harmful request
```

## Best Practices

1. **Start Small**: Begin with a few plugins and strategies, then expand coverage
2. **Regular Testing**: Run red team tests regularly during development
3. **Baseline Establishment**: Create a baseline of expected behavior before testing
4. **Iterative Improvement**: Use test results to improve prompts and guardrails
5. **Documentation**: Keep track of which vulnerabilities have been addressed
6. **Custom Plugins**: Create custom plugins for application-specific vulnerabilities

## Example Configuration

Here's a complete example of a `promptfooconfig.yaml` file:

```yaml
description: 'Red team testing for my chatbot'

targets:
  - id: 'my-chatbot'
    config:
      url: 'http://localhost:5000/api/chat'
      method: 'POST'
      headers:
        'Content-Type': 'application/json'
      body:
        message: '{{prompt}}'

redteam:
  numTests: 50
  
  plugins:
    - id: 'prompt-injection'
      numTests: 10
    - id: 'jailbreak'
      numTests: 10
    - id: 'harmful:hate'
      numTests: 10
    - id: 'pii'
      numTests: 10
    - id: 'overreliance'
      numTests: 10
  
  strategies:
    - id: 'jailbreak'
    - id: 'rot13'
    - id: 'base64'
    - id: 'multilingual'
      config:
        languages: ['es', 'fr', 'de', 'zh']

outputPath: './redteam-results.json'
```

## Running Tests

After configuration, run your red team tests with:

```bash
# Run the red team evaluation
promptfoo redteam run

# View results in a web interface
promptfoo redteam report
```

## Additional Resources

- [Promptfoo GitHub Repository](https://github.com/promptfoo/promptfoo)
- [Interesting Read](https://www.promptfoo.dev/blog/ai-safety-vs-security/)
- [Example configurations](https://github.com/promptfoo/promptfoo/tree/main/examples)

---

*This guide covers the essentials of using promptfoo for LLM security testing. For more detailed information, always refer to the [official documentation](https://www.promptfoo.dev/docs/).*

