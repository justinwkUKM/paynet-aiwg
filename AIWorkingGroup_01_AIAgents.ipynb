{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ad34bdfb"
      },
      "source": [
        "### Installation\n",
        "\n",
        "This cell installs the necessary libraries from the `requirements.txt` file. This ensures that all dependencies required for the notebook to run correctly are installed in the Colab environment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91619637"
      },
      "source": [
        "!pip install -r requirements.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05cee6da"
      },
      "source": [
        "### API Key and URL Setup\n",
        "\n",
        "This cell imports the `litellm` and `openai` libraries, as well as `userdata` from `google.colab` to securely access secrets stored in the Colab environment. It then retrieves the `LITELLM_API_KEY`, `LITELLM_URL`, and `MODEL` from Colab's user data secrets, assigning them to variables for later use."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3cc9f18"
      },
      "source": [
        "import litellm\n",
        "from openai import OpenAI\n",
        "from google.colab import userdata\n",
        "\n",
        "LITELLM_API_KEY = userdata.get('LITELLM_API_KEY')\n",
        "LITELLM_URL = userdata.get('LITELLM_URL')\n",
        "MODEL = userdata.get('LITELLM_MODEL')"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d63ac53c"
      },
      "source": [
        "### Initialize OpenAI Client\n",
        "\n",
        "This cell initializes an `OpenAI` client instance. It uses the `LITELLM_URL` as the `base_url` to point to the LiteLLM proxy and the `LITELLM_API_KEY` for authentication. This client will be used to interact with the language model through the LiteLLM proxy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7d13ba7f"
      },
      "source": [
        "# Initialize client with your proxy URL\n",
        "client = OpenAI(\n",
        "    base_url=LITELLM_URL,  # Your proxy URL\n",
        "    api_key=LITELLM_API_KEY             # Your proxy API key\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "212b2ad6"
      },
      "source": [
        "### Generate Non-Streaming Response\n",
        "\n",
        "This cell demonstrates how to generate a non-streaming response from the language model using the initialized `client`. It sends a prompt asking for a two-sentence bedtime story about a unicorn and stores the entire response in the `response` variable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e1f94876"
      },
      "source": [
        "# non streaming response\n",
        "response = client.responses.create(\n",
        "    model=MODEL,\n",
        "    input=\"Tell me a two sentence bedtime story about a unicorn.\",\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05145a60"
      },
      "source": [
        "### Display Non-Streaming Response\n",
        "\n",
        "This cell displays the complete `response` object obtained from the previous non-streaming call. This allows you to see the full structure of the response, including metadata, usage information, and the generated content."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54b66c74"
      },
      "source": [
        "response"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4a9716e"
      },
      "source": [
        "### Generate Streaming Response\n",
        "\n",
        "This cell is similar to the non-streaming example but configures the client for streaming responses. It sends the same prompt and prints the response as it is generated, which can be useful for larger outputs or interactive applications."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38a09c42",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4139af9-622c-4cb1-98d0-824ec8a4e00e"
      },
      "source": [
        "# Streaming response\n",
        "response = client.responses.create(\n",
        "    model=MODEL,\n",
        "    input=\"Tell me a four sentence bedtime poem about a unicorn from klang valley.\",\n",
        "    stream=True,\n",
        ")\n",
        "\n",
        "full_text = []\n",
        "\n",
        "for event in response:\n",
        "    # Check if the event is a text delta\n",
        "    if event.type == \"response.output_text.delta\":\n",
        "        chunk = event.delta\n",
        "        print(chunk, end=\"\", flush=True)   # stream piece by piece\n",
        "        full_text.append(chunk)\n",
        "    elif event.type == \"response.completed\":\n",
        "        print(\"\\n\\n[sstreameeerrrrred successfully!!!]\")\n",
        "    elif event.type == \"response.error\":\n",
        "        print(f\"\\n[error] {event.error}\")\n",
        "\n",
        "final_text = \"\".join(full_text)\n",
        "print(\"\\nFinal text:\", final_text)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here's a gentle bedtime poem about a unicorn from Klang Valley:\n",
            "\n",
            "In Klang Valley where the city lights gleam bright,\n",
            "A magical unicorn appears each starry night.\n",
            "With silver horn and mane of flowing white,\n",
            "She sprinkles dreams until the morning light.\n",
            "\n",
            "[sstreameeerrrrred successfully!!!]\n",
            "\n",
            "Final text: Here's a gentle bedtime poem about a unicorn from Klang Valley:\n",
            "\n",
            "In Klang Valley where the city lights gleam bright,\n",
            "A magical unicorn appears each starry night.\n",
            "With silver horn and mane of flowing white,\n",
            "She sprinkles dreams until the morning light.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "488ef7eb"
      },
      "source": [
        "### Import Langgraph Components\n",
        "\n",
        "This cell imports necessary components from the `langgraph` library, specifically `create_react_agent` for building reactive agents. It also imports `OpenAI` and `load_dotenv` (although `load_dotenv` is not strictly necessary when using Colab secrets) and `ChatLiteLLM` from `langchain_litellm` for integrating LiteLLM with Langchain, and `InMemorySaver` for managing conversation history."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "be519944"
      },
      "source": [
        "from langgraph.prebuilt import create_react_agent\n",
        "import os\n",
        "from openai import OpenAI\n",
        "from dotenv import load_dotenv\n",
        "from langchain_litellm import ChatLiteLLM\n",
        "from langgraph.checkpoint.memory import InMemorySaver"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19e2758b"
      },
      "source": [
        "### Define Langchain Model with LiteLLM\n",
        "\n",
        "This cell defines the language model to be used within the Langchain framework, leveraging the LiteLLM integration. It initializes `ChatLiteLLM` with the previously retrieved `MODEL`, `LITELLM_URL`, and `LITELLM_API_KEY`. It also sets `custom_llm_provider` to \"openai\" to ensure compatibility with Langchain's OpenAI integration, enables streaming, and sets the temperature to 0 for deterministic output."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8e31a1e5"
      },
      "source": [
        "# 1. Define the model\n",
        "model = ChatLiteLLM(\n",
        "    model=MODEL, # configured in LiteLLM\n",
        "    api_base=LITELLM_URL, # URL to the LiteLLM server\n",
        "    api_key=LITELLM_API_KEY, # API key for LiteLLM\n",
        "    # organization=os.getenv(\"ORG\"), # organization configured in LiteLLM\n",
        "    custom_llm_provider=\"openai\", # mimic OpenAI API\n",
        "    temperature=0.0, # temperature for the model\n",
        "    streaming=True, # enable streaming\n",
        "    verbose=True, # enable verbose logging\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "54d6d930"
      },
      "source": [
        "### Define Checkpointer and Tool\n",
        "\n",
        "This cell sets up an `InMemorySaver` as a checkpointer to store the conversation history in memory. It also defines a simple Python function `get_weather` that acts as a tool for the agent. This tool takes a city name as input and returns a hardcoded string indicating sunny weather. In a real application, this would typically involve calling an external weather API."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7aa91aa"
      },
      "source": [
        "checkpointer = InMemorySaver()\n",
        "\n",
        "def get_weather(city: str) -> str:\n",
        "    \"\"\"Get weather for a given city.\"\"\"\n",
        "    print(f\"Getting weather for city: {city}\")\n",
        "    return f\"It's always sunny in {city}!\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5dcc2447"
      },
      "source": [
        "### Create React Agent\n",
        "\n",
        "This cell creates a \"React\" agent using `create_react_agent`. This agent is designed to react to user input and decide whether to use an available tool (like the `get_weather` function) or directly respond. It's initialized with the `model`, the list of available `tools`, a system `prompt`, and the `checkpointer` for managing conversation state."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ab43bf6"
      },
      "source": [
        "agent = create_react_agent(\n",
        "    model=model,\n",
        "    tools=[get_weather],\n",
        "    prompt=\"You are a helpful assistant\",\n",
        "    checkpointer=checkpointer\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ea82afdd"
      },
      "source": [
        "### Define Thread ID\n",
        "\n",
        "This cell defines a dictionary `thread_id` that will be used to identify a specific conversation thread. This is important for the checkpointer to store and retrieve the correct conversation history."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cf42aac7"
      },
      "source": [
        "thread_id = {\"configurable\": {\"thread_id\": \"thread-1\"}}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3270dc25"
      },
      "source": [
        "### Invoke Agent with Initial Message\n",
        "\n",
        "This cell invokes the `agent` with an initial message from the user (\"hi! i am from kuala lumpur\"). The `thread_id` is passed in the configuration to associate this message with the defined thread. The agent processes this message and generates a response."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d21252f6"
      },
      "source": [
        "agent.invoke(\n",
        "    {\"messages\": [{\"role\": \"user\", \"content\": \"hi! i am from kuala lumpur\"}]},\n",
        "    {\"configurable\": {\"thread_id\": \"1\"}},\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d04192db"
      },
      "source": [
        "### Invoke Agent to Get Weather\n",
        "\n",
        "This cell invokes the `agent` again, this time with a message asking about the weather in the user's city (\"What is the weather in my city?\"). Since the agent remembers the previous conversation in the same thread (due to the checkpointer and thread ID), it knows the user is from Kuala Lumpur and can use the `get_weather` tool."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "953e772b"
      },
      "source": [
        "response = agent.invoke(\n",
        "    {\"messages\": [{\"role\": \"user\", \"content\": \"What is the weather in my city?\"}]},\n",
        "    {\"configurable\": {\"thread_id\": \"1\"}},\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33b82865"
      },
      "source": [
        "### Print Final Response Object\n",
        "\n",
        "This cell prints the complete `response` object from the agent's second invocation. This object contains the entire conversation history for the specified thread, including the agent's thinking process (like identifying the need to use the `get_weather` tool) and the final generated response."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "563e4cf0"
      },
      "source": [
        "print(\"Final response object:\", response)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1f48e695"
      },
      "source": [
        "### Print Final Output\n",
        "\n",
        "This cell extracts and prints only the content of the last message in the `response` object. This represents the final, human-readable response from the agent after it has processed the user's query and used any necessary tools."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c952c2e0"
      },
      "source": [
        "print(\"Final Output -> \", response[\"messages\"][-1].content)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import AnyMessage\n",
        "from typing_extensions import TypedDict\n",
        "\n",
        "class State(TypedDict):\n",
        "    messages: list[AnyMessage]\n",
        "    extra_field: int"
      ],
      "metadata": {
        "id": "yc2ZJamdVfkL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import AIMessage\n",
        "\n",
        "def node(state: State):\n",
        "    messages = state[\"messages\"]\n",
        "    new_message = AIMessage(\"Hello!\")\n",
        "    return {\"messages\": messages + [new_message], \"extra_field\": 10}"
      ],
      "metadata": {
        "id": "4jkyMrcGbsSU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.graph import StateGraph\n",
        "\n",
        "builder = StateGraph(State)\n",
        "builder.add_node(node)\n",
        "builder.set_entry_point(\"node\")\n",
        "graph = builder.compile()"
      ],
      "metadata": {
        "id": "Qo0CI4V1e3od"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "display(Image(graph.get_graph().draw_mermaid_png()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "id": "d_E9sr8JcQqA",
        "outputId": "4db4d3aa-ce6a-48b1-a840-5149e0c617eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ffmdyd23fD6M"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GNbBNx1ngnZQ"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qi4aaVC0gn5b"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}